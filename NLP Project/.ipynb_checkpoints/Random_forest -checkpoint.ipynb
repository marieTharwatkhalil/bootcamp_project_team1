{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy  as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_model(search_model):\n",
    "    \"\"\"this function takes the search model then train and test the model \n",
    "    and return predicted labels,confusion_matrix,classification_report, accuracy_score\"\"\"\n",
    "    \n",
    "    print(\"search_model---> Done\")\n",
    "    search_model.fit(X_train,y_train)\n",
    "    print(\"fitting the model--> Done\")\n",
    "    best_search = search_model.best_estimator_\n",
    "    print(\"choosing the best values--->Done\")\n",
    "    y_pred_search=best_search.predict(X_test)\n",
    "    print(\"predicting labels---> Done\")\n",
    "    \n",
    "    V1=y_pred_search\n",
    "    V2=confusion_matrix(y_test,y_pred_search)\n",
    "    V3=classification_report(y_test,y_pred_search)\n",
    "    V4=accuracy_score(y_test, y_pred_search)*100\n",
    "    V5= best_search\n",
    "    print(\"Done\")\n",
    "    #evaluating the grid search best model \n",
    "    #return y_pred_search, confusion_matrix(y_test,y_pred_search),classification_report(y_test,y_pred_search), accuracy_score(y_test, y_pred_search)*100\n",
    "    return  V1, V2, V3, V4, V5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clnd_data=pd.read_csv(\"correct_labels_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sweet smooth taste every drop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific product drops food straight mixed aga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best food market mans food leaves hoppy aftert...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great refreshing taste weak food safe ingredie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purchased item make mimosas left mimosas delic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Label\n",
       "0                      sweet smooth taste every drop      1\n",
       "1  terrific product drops food straight mixed aga...      1\n",
       "2  best food market mans food leaves hoppy aftert...      1\n",
       "3  great refreshing taste weak food safe ingredie...      1\n",
       "4  purchased item make mimosas left mimosas delic...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clnd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vctrr= TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_features = tfidf_vctrr.fit_transform(clnd_data['Reviews']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf_features\n",
    "Y=clnd_data[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model on 80% of the datset \n",
    "rand_forest = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model on 20% of the dataset \n",
    "#predicting the labels for the test set \n",
    "y_pred = rand_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6   7  19]\n",
      " [  0  32  18]\n",
      " [  2  18 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.19      0.30        32\n",
      "           0       0.56      0.64      0.60        50\n",
      "           1       0.91      0.95      0.93       402\n",
      "\n",
      "    accuracy                           0.87       484\n",
      "   macro avg       0.74      0.59      0.61       484\n",
      "weighted avg       0.86      0.87      0.85       484\n",
      "\n",
      "Accuracy:  86.77685950413223\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model \n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the model performs better without tuning so we will save this random forest model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model to pickle file \n",
    "with open(\"model_random_forest.pickle\",\"wb\") as f:\n",
    "    pickle.dump(rand_forest,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the model \n",
    "with open(\"model_random_forest.pickle\",\"rb\") as f:\n",
    "    md=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  0,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  0,  0,\n",
       "        1,  1,  1,  1,  0,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  0,  1,  1,  1,\n",
       "        1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  0,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  1,\n",
       "        1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  0,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  0,  1,  1,  1,\n",
       "        0,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,\n",
       "        1,  1,  1,  1,  1,  1,  0,  1, -1,  0,  0,  1,  1,  1,  1,  0,  1,\n",
       "        1,  1,  0,  1,  0,  1,  0,  1,  1,  1,  0,  0,  1,  1,  1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  0,  1,  1,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the imported model to predict the labels for the test set \n",
    "md.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# searching for the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#setting parameters for random search with 3 folds cross validation \n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of Random forest classifier \n",
    "rf = RandomForestClassifier()\n",
    "#random search with 3 folds cross validation & 100 iterations \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_model---> Done\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 130.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the model--> Done\n",
      "choosing the best values--->Done\n",
      "predicting labels---> Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pred_rand_search_labels,conf_mtrx_rand_search,class_report_rand_search,acc_score_rand_search,model_rand_search = build_search_model(rf_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   1  27]\n",
      " [  0  18  32]\n",
      " [  2   3 397]]               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.12      0.21        32\n",
      "           0       0.82      0.36      0.50        50\n",
      "           1       0.87      0.99      0.93       402\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       484\n",
      "   macro avg       0.79      0.49      0.55       484\n",
      "weighted avg       0.85      0.87      0.83       484\n",
      " random search Accuracy:  86.57024793388429\n"
     ]
    }
   ],
   "source": [
    "print(conf_mtrx_rand_search,class_report_rand_search,\"random search Accuracy: \",acc_score_rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search parameters \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [10,100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Create an instance of random forest classifier model\n",
    "rf_G_search = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Create an instance of the grid search model \n",
    "grid_search = GridSearchCV(estimator = rf_G_search, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_model---> Done\n",
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the model--> Done\n",
      "choosing the best values--->Done\n",
      "predicting labels---> Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pred_grid_search_labels,conf_mtrx_grid_search,class_report_grid_search,acc_score_grid_search,model_grid_search = build_search_model(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0  31]\n",
      " [  0   6  44]\n",
      " [  0   0 402]]               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.03      0.06        32\n",
      "           0       1.00      0.12      0.21        50\n",
      "           1       0.84      1.00      0.91       402\n",
      "\n",
      "    accuracy                           0.85       484\n",
      "   macro avg       0.95      0.38      0.40       484\n",
      "weighted avg       0.87      0.85      0.79       484\n",
      " Grid search Accuracy:  84.50413223140497\n"
     ]
    }
   ],
   "source": [
    "print(conf_mtrx_grid_search,class_report_grid_search,\"Grid search Accuracy: \",acc_score_grid_search )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model to pickle file \n",
    "with open(\"model_grid_search.pickle\",\"wb\") as f:\n",
    "    pickle.dump(model_grid_search,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=100, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the model \n",
    "with open(\"model_grid_search.pickle\",\"rb\") as f:\n",
    "    md2=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2328    1\n",
       "1742    1\n",
       "810     1\n",
       "2014    1\n",
       "618    -1\n",
       "1300    1\n",
       "1454    1\n",
       "2410    1\n",
       "2394    0\n",
       "743    -1\n",
       "1091    1\n",
       "646     1\n",
       "793    -1\n",
       "2028    1\n",
       "1815    1\n",
       "2101    1\n",
       "667     1\n",
       "1919    1\n",
       "1452    1\n",
       "1205    1\n",
       "806    -1\n",
       "1023    1\n",
       "882    -1\n",
       "651     0\n",
       "1248    1\n",
       "2037    1\n",
       "1448    1\n",
       "390     1\n",
       "1393    1\n",
       "1476    1\n",
       "       ..\n",
       "1607    0\n",
       "418     1\n",
       "2408    1\n",
       "1630    0\n",
       "1467    1\n",
       "1724    1\n",
       "254     1\n",
       "1397    1\n",
       "1493    1\n",
       "978     1\n",
       "1330    1\n",
       "634     1\n",
       "300     1\n",
       "1430    1\n",
       "1712    1\n",
       "259     1\n",
       "1674    1\n",
       "30      1\n",
       "1450    1\n",
       "1799   -1\n",
       "574     1\n",
       "1074    0\n",
       "963     1\n",
       "1051    1\n",
       "2086    1\n",
       "1814    1\n",
       "1388    1\n",
       "2270    1\n",
       "794     1\n",
       "682     1\n",
       "Name: Label, Length: 484, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
